---
title: "HRV_Bayesian"
author: "Conrado Eiroa-Solans"
---

BACKGROUND INFO: 

Bayes Theorem: 
  Posterior = (probability*prior)/normalization
  P. of posterior = P of A given that B has ocurred (trains estimate to become less wrong)
  E.g. One of three sites (A,B,C) has oil. If B doesn't have it, probabilities rise from .33 to .5 for A & B
  
Steps: 
  Specify 'priors' (assumptions)
  Create a model mapping the training inputs to the training outputs
  Draw samples from the posterior distribution for the model parameters.

---


SET UP DATA
```{r}
library(tidyverse)
library(tidylog)

setwd("/Users/Conrad/Desktop/Academic/Undergrad/Research/Stanford_Lab/Spring/SBER_Data/")

#Read Invidivual differences data (pre-PSG)
individual_diff <- read.csv("FinalDATA104_psqi_rescored.csv") %>%
  select(Bruxism_groups, Bruxism_sum, partID, gender, age, ethn, starts_with("race_"), starts_with("erq"),   starts_with("cerq"), starts_with("ders")) %>%
  dplyr::rename(id = partID)

#Read HRV data (PSG)
hrv <- read.csv("HRV_All_Epoch_Night.csv") %>% 
  select(SID,quantile,Stage,RRmean,HRmean,SDNN,RMSSD,pNN50,Total,LFovHF,LF,HF,HFnu,MPF) %>% 
  dplyr::rename(id = SID)

#Read Task data (Post-PSG *Task*)
task <- read.csv("IER_psg_physio_combined_participant_level.csv") %>%
  rename(id = participant)

#Eliminate non-Sleep Stages + outliers
hrv = subset(hrv,(hrv$Stage!=7)) 
hrv$HF[hrv$HF > 7500] <- NA #very generous limits
hrv$LF[hrv$LF > 7500] <- NA 
hrv$SDNN[hrv$SDNN > 300] <- NA #very generous limits
hrv$RMSSD[hrv$RMSSD > 300] <- NA

#Create joint variables and erase old ones
hrv_inddiff = left_join(hrv,individual_diff, by="id") 
hrv_task = left_join(hrv, task, by = "id")
hrv_all = left_join(hrv_inddiff, task, by = "id")

rm(individual_diff)
rm(task)
```


Distributions of variables of interest for Pre-PSG & HRV (Task data requires additional step): 
```{r}
#Pre-PSG
hist(hrv_inddiff$erqf_cr)
hist(hrv_inddiff$erqdf_sum)
hist(hrv_inddiff$cerq_pref)  
hist(log(hrv_inddiff$derssf_na))

#HRV
hist(hrv_inddiff$HRmean)
hist(log(hrv_inddiff$SDNN))
hist(log(hrv_inddiff$RMSSD))
hist(log(hrv_inddiff$HF))
hist(log(hrv_inddiff$LF))
hist(hrv_inddiff$HFnu)

#Task
hist(log(1 + hrv_task$distract_val_change))
hist(log(1 + hrv_task$distract_val_change)) #Valence 
hist(log(1 + hrv_task$reappraise_val_change))
hist(log(1 + hrv_task$distract_arou_change)) #Arousal
hist(log(1 + hrv_task$reappraise_arou_change))
hist(log(1 + hrv_task$scl_change_pic_distract)) #SCL
hist(log(1 + hrv_task$scl_change_pic_reappraise))
hist(log(1 + hrv_task$emg_corr_change_distract)) #EMG
hist(log(1 + hrv_task$emg_corr_change_reappraise))

```

Log-transform non-normal variables for Pre-PSG & HRV
```{r}
#Pre-PSG
hrv_inddiff$dessf_na = log(hrv_inddiff$derssf_na)

#HRV
hrv_inddiff$SDNN = log(hrv_inddiff$SDNN)
hrv_inddiff$RMSSD = log(hrv_inddiff$RMSSD)
hrv_inddiff$HF = log(hrv_inddiff$HF)
hrv_inddiff$LF = log(hrv_inddiff$LF)

#Task* (see below) 
hrv_task$reappraise_arou_change = log(1+hrv_task$reappraise_arou_change)
```
  *To attain only positive values (to log-transform), I added +1 to all observations. 
       *Originally   +1   Now (log)*
         -x         0.x     -x
          0          1       0
         +x        x+1       x
         
         


Tables of Means & SD
```{r}
hrv_all %>% group_by(Stage) %>% summarize(mean_HR = mean(HRmean, na.rm = T), mean_SDNN = mean(SDNN, na.rm = T), mean_RMSSD = mean(RMSSD, na.rm = T), mean_HF = mean(HF, na.rm = T), mean_LF = mean(LF, na.rm = T), mean_HFnu=mean(HFnu, na.rm = T), mean_TP = mean(Total, na.rm = T))    

hrv_all %>% group_by(Stage) %>% summarize(sd_HR = sd(HRmean, na.rm = T), sd_SDNN = sd(SDNN, na.rm = T), sd_RMSSD = sd(RMSSD, na.rm = T), sd_HF = sd(HF, na.rm = T), sd_LF = sd(LF, na.rm = T), sd_HFnu=sd(HFnu, na.rm = T), sd_TP = sd(Total, na.rm = T))

```


Visualization
```{r}
#hrv_gender= hrv_inddiff %>%filter(gender!= 3)
ggplot(hrv_all,aes(x = as.factor(Stage), y = Total)) +
  geom_violin() +
  geom_jitter(col="blue") +
  stat_summary(fun.y = mean, geom = "point", col="red") +
  xlab("Stage") +
  ylim(0,20000) 
```






BAYESIAN STATISTICS: does HF(DV) predict DERS (IV)? 
(3 options; from simple to complex / more control)


1) Brms package (simplest):
```{r}
#Run model
library(brms)
m_test_lm <- 
  brm(data = hrv, family = gaussian,
      scale(HF, scale=TRUE) ~ 1 + scale(HRmean,scale=TRUE),
      prior = c(prior(normal(0,1), class = Intercept),
                prior(normal(0,1), class = b),
                prior(cauchy(0,2), class = sigma)),
      save_all_pars = T,
      file = "/Users/Conrad/Desktop/Academic/Undergrad/Research/Stanford_Lab/Spring/SBER_Data/hrv_bayesian.csv",
      iter = 5000, warmup = 2000, chains = 4, cores = 4,
      control = list(adapt_delta = 0.99))

#Plot distributions
plot(m_test_lm)

#Statistics
posterior_summary(m_test_lm) %>%
  round(digits = 2)
```



2) rstan functions (moderate)
```{r}
library(rstan)
library(rstanarm)
glm_post1 <- stan_glm(derssf_general~HF, data=hrv_all, family=gaussian) # gaussian / binomial / poisson
summary(glm_post1) #sigma = sd; mean_PPD = mean of posterior predictive samples; log posterior = likelyhood
  
    #Rhat = variance between chains (groups; =simulation vs original; below 1.1 = model has converged)

pp_check(glm_post1) #Posterior predictive check
stan_hist(glm_post1, pars=c("HF"), bins=40) #Histogram of posterior sample
```


```{r}
#Mean and confidence intervals of HF
post_samps_speed <- as.data.frame(glm_post1, pars=c("HF"))[,"HF"]
mean_HF <- mean(post_samps_speed) # posterior mean 
confidenceInterval_HF <- quantile(post_samps_speed, probs=c(0.05, 0.95)) # posterior 90% Confidence Interval 

```


```{r}
#Compare posterior to prior
glm_fit = glm(derssf_general~HF, data=hrv_all, family=gaussian)
summary(glm_fit)

prior_summary(glm_post1)

posterior_vs_prior(glm_post1, group_by_parameter = TRUE, pars=c("(Intercept)"))
posterior_vs_prior(glm_post1, group_by_parameter = TRUE, pars=c("HF", "sigma"))

glm_post2 <- stan_glm(derssf_general~HF, data=hrv_all, family=gaussian, prior=normal(2,0.5,autoscale=FALSE))
posterior_vs_prior(glm_post2, pars=c("HF"), group_by_parameter = TRUE)
summary(glm_post2)

```



3) Rstan full control (complex)      #make sure "model.stan" is in the same directory 
```{r}
library(rstan)
library(rstanarm)

rstan_options(auto_write = TRUE)
```


```{r}
#Prepare Data
HF = scale(log(hrv_inddiff$HF), center = TRUE, scale = TRUE)
DERS = scale(log(hrv_inddiff$derssf_general), center = TRUE, scale = TRUE)
df_data = na.omit(data.frame(cbind(HF,DERS)))
df_data = df_data %>% rename(DERS = X2)  %>% rename(HF = X1)

x = df_data$DERS
y = df_data$HF

data = list(N = length(x), x=x, y=y)
rm(HF, DERS) #keep global environment small


#Visualize Data
qplot(df_data$DERS, df_data$HF)
hist(df_data$DERS)
hist(df_data$HF)
```

```{r}
#Fit model using rstan
require(rstan)
fit = stan(file = '/Users/Conrad/Desktop/Academic/Undergrad/Research/Stanford_Lab/Spring/model.stan', data = data)
#Findings
summary(fit)

```


```{r}
#Plot fitness of line 
plot(x,y, main = "Fitness of line with posterior intervals")
params = rstan::extract(fit)  #extract conflicts with tidyr, so need to clarify
alpha = mean(params$alpha)
beta = mean(params$beta)
abline(a = alpha, b= beta) 

#Obtain posterior interval of posterior draws from parameters (95 percentile in x)
xr = seq(3,4.5,0.0001) #sequence from min to max of x by 0.0001 
yCI = sapply(xr, function(k) quantile(params$beta * k + params$alpha, probs = c(0.05,0.95)))
lines(xr, yCI[1,], col='red')
lines(xr, yCI[2,], col='red')
```


Check #1: Posterior predictive check
```{r}
#Run refit of the model (including generated quantities)
require(rstan)
fit = stan(file = '/Users/Conrad/Desktop/Academic/Undergrad/Research/Stanford_Lab/Spring/model.stan', data = data)

#Compare distribution of our data with simulated data
plot(density(y), xlim=c(-4,4), ylim=c(0,0.5),  main = "Distribution: observed vs simulated data")  
                #values (~0.5) around min & max of density of y
params = rstan::extract(fit) 
for(i in 1:10){lines(density(params$y_sim[i,]), col= 'red')}#distribution of simulated data (10 posterio param draws)
                                                            # bad fit = chosen priors are bad (choose different)
```

Check #2:Parameters: Observed vs Simulated data
```{r}
#Compare parameters of observed and simulated data 
y_new = params$y_sim[20,] #recover params of 20th simulated draw
data_new = list(N=length(x), x=x, y=y_new) #replace observed with simulated
require(rstan)
fit_new = stan(file = '/Users/Conrad/Desktop/Academic/Undergrad/Research/Stanford_Lab/Spring/model.stan', data = data_new)
params_new = extract(fit_new)

#Plot
plot(density(params$alpha), main = 'Alpha parameters: observed vs simulated data')
lines(density(params_new$alpha), col = 'red')
main="Main title"
plot(density(params$beta), main = 'Beta parameters: observed vs simulated data')
lines(density(params_new$beta), col = 'red')

```







